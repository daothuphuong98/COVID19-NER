{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daothuphuong98/COVID19-NER/blob/main/BiLSTM_CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq9beqYrBWSH",
        "outputId": "a23662e9-4010-408c-bb9b-a987f386418d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'PhoNER_COVID19'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 58 (delta 23), reused 41 (delta 18), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (58/58), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/VinAIResearch/PhoNER_COVID19.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX-NSlpCu6kA",
        "outputId": "249f9927-849c-4905-ee59-df2d721e7062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-cdcl4lia\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-cdcl4lia\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 9.0 MB/s \n",
            "\u001b[?25hCollecting gensim==4.1.2\n",
            "  Downloading gensim-4.1.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 104.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from keras-contrib==2.0.8) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from gensim==4.1.2) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim==4.1.2) (6.3.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim==4.1.2) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Building wheels for collected packages: keras-contrib, seqeval\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101076 sha256=5a21ec1c6976532a39f11ed020177da7aea478c248ac4e48c0a35777b85a9ce1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3_m767eg/wheels/67/d2/f4/96ae3c3c62d1e05abfc8860ad0c1207794726d44ebbbb547f3\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=35cf1ba6cb5a11f1a2abbf5b4314f532016d8f03711dc03425a98d170ad33b2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built keras-contrib seqeval\n",
            "Installing collected packages: tensorflow-addons, seqeval, keras-contrib, gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.1.2 keras-contrib-2.0.8 seqeval-1.2.2 tensorflow-addons-0.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval tensorflow_addons gensim==4.1.2 git+https://www.github.com/keras-team/keras-contrib.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLNMGG8lvEze",
        "outputId": "500a7a5e-6920-4818-98fe-e89bb0cc712d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-25-69eaf9fad717>:19: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  pd.set_option('display.max_colwidth', -1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow_addons.text import crf_log_likelihood, crf_decode\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed, Input, BatchNormalization, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import initializers, Sequential\n",
        "from seqeval.metrics import f1_score, classification_report\n",
        "from keras_contrib.layers import CRF\n",
        "import tensorflow.keras.optimizers as Optimizer\n",
        "import plotly.express as px\n",
        "from gensim.models import FastText\n",
        "pd.set_option('display.max_colwidth', -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaW8nEUyQitV"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LO5gHyUfQhyZ"
      },
      "outputs": [],
      "source": [
        "def handle_file(link):\n",
        "    with open(link) as f:\n",
        "        contents = f.readlines()\n",
        "    idx_sentence, idx_arr, word, tag = 0, [], [], []\n",
        "    for line in contents:\n",
        "        arr_info = line.split(' ')\n",
        "        # print(arr_info)\n",
        "        if len(arr_info) == 1:\n",
        "            idx_sentence += 1\n",
        "            continue\n",
        "        word.append(arr_info[0])\n",
        "        tag.append(arr_info[1].replace('\\n', ''))\n",
        "        idx_arr.append(idx_sentence)\n",
        "    return pd.DataFrame(\n",
        "        data = {\n",
        "            'idx': idx_arr,\n",
        "            'word': word,\n",
        "            'tag': tag\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrybe1LBSyxL"
      },
      "outputs": [],
      "source": [
        "word_train_data = handle_file('/content/PhoNER_COVID19/data/word/train_word.conll')\n",
        "word_test_data = handle_file('/content/PhoNER_COVID19/data/word/test_word.conll')\n",
        "word_val_data = handle_file('/content/PhoNER_COVID19/data/word/dev_word.conll')\n",
        "\n",
        "word_train_data['word_process'] = word_train_data['word'].apply(lambda x: re.sub('[0-9]+', \"<NUM>\", x).lower())\n",
        "word_test_data['word_process'] = word_test_data['word'].apply(lambda x: re.sub('[0-9]+', \"<NUM>\", x).lower())\n",
        "word_val_data['word_process'] = word_val_data['word'].apply(lambda x: re.sub('[0-9]+', \"<NUM>\", x).lower())\n",
        "\n",
        "filter_string = '?!\"/\\{}().,'\n",
        "word_train_data = word_train_data[word_train_data['word_process'].apply(lambda x: x not in filter_string)]\n",
        "word_test_data = word_test_data[word_test_data['word_process'].apply(lambda x: x not in filter_string)]\n",
        "word_val_data = word_val_data[word_val_data['word_process'].apply(lambda x: x not in filter_string)]\n",
        "\n",
        "word_train_data_group = word_train_data.groupby('idx').agg({'word_process': ' '.join, 'word': ' '.join, 'tag': list}) \n",
        "word_test_data_group = word_test_data.groupby('idx').agg({'word_process': ' '.join, 'word': ' '.join, 'tag': list}) \n",
        "word_val_data_group = word_val_data.groupby('idx').agg({'word_process': ' '.join, 'word': ' '.join, 'tag': list}) \n",
        "\n",
        "word_train_data_group['len_tag'] = word_train_data_group['tag'].apply(lambda x: len(x))\n",
        "word_val_data_group['len_tag'] = word_val_data_group['tag'].apply(lambda x: len(x))\n",
        "word_test_data_group['len_tag'] = word_test_data_group['tag'].apply(lambda x: len(x))\n",
        "\n",
        "# train_data_group = train_data_group[train_data_group['len_tag'] <= 55].reset_index()\n",
        "# val_data_group = val_data_group[val_data_group['len_tag'] <= 55].reset_index()\n",
        "# test_data_group = test_data_group[test_data_group['len_tag'] <= 55].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4jG2m7Y4MAKN",
        "outputId": "f70bfbf0-ee6e-454e-86e8-4f00f29c5089"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3d97e78c-f877-47fb-8fac-95ebc8f3e6c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_process</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>len_tag</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>idx</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>tại hà_nội bệnh_nhân đi làm và gặp_gỡ bạn_bè tại nhiều nơi</td>\n",
              "      <td>Tại Hà_Nội bệnh_nhân đi làm và gặp_gỡ bạn_bè tại nhiều nơi</td>\n",
              "      <td>[O, B-LOCATION, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004</th>\n",
              "      <td>trước đó ngày &lt;num&gt;/&lt;num&gt; nữ doanh_nhân đi từ việt_nam sang mỹ có quá_cảnh hàn_quốc</td>\n",
              "      <td>Trước đó ngày 22/2 nữ doanh_nhân đi từ Việt_Nam sang Mỹ có quá_cảnh Hàn_Quốc</td>\n",
              "      <td>[O, O, O, B-DATE, O, O, O, O, B-LOCATION, O, B-LOCATION, O, O, B-LOCATION]</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3010</th>\n",
              "      <td>ngày &lt;num&gt;/&lt;num&gt; bệnh_nhân ra hà_nội</td>\n",
              "      <td>Ngày 25/7 bệnh_nhân ra Hà_Nội</td>\n",
              "      <td>[O, B-DATE, O, O, B-LOCATION]</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>chồng của bà đã tử_vong do covid - &lt;num&gt; và suy thận mạn</td>\n",
              "      <td>Chồng của bà đã tử_vong do Covid - 19 và suy thận mạn</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, B-SYMPTOM_AND_DISEASE, I-SYMPTOM_AND_DISEASE, I-SYMPTOM_AND_DISEASE]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>913</th>\n",
              "      <td>bé trai &lt;num&gt; tuổi được ra viện sáng nay ngụ phường cát_lái quận &lt;num&gt;</td>\n",
              "      <td>Bé trai 10 tuổi được ra viện sáng nay ngụ phường Cát_Lái quận 2</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, B-LOCATION, I-LOCATION, B-LOCATION, I-LOCATION]</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>cô từ mỹ_về quá_cảnh ở philippines nhập_cảnh việt_nam ngày &lt;num&gt; - &lt;num&gt;</td>\n",
              "      <td>Cô từ Mỹ_về quá_cảnh ở Philippines nhập_cảnh Việt_Nam ngày 13 - 3</td>\n",
              "      <td>[O, O, B-LOCATION, O, O, B-LOCATION, O, B-LOCATION, O, B-DATE, I-DATE, I-DATE]</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>theo đó ca bệnh &lt;num&gt; bệnh_nhân &lt;num&gt; là nam &lt;num&gt; tuổi tân_bình thành_phố hải_dương</td>\n",
              "      <td>Theo đó ca bệnh 963 bệnh_nhân 963 là nam 30 tuổi Tân_Bình thành_phố Hải_Dương</td>\n",
              "      <td>[O, O, O, O, B-PATIENT_ID, O, B-PATIENT_ID, O, B-GENDER, B-AGE, O, B-LOCATION, B-LOCATION, I-LOCATION]</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3420</th>\n",
              "      <td>ngày &lt;num&gt;/&lt;num&gt; anh này đi chuyến ak&lt;num&gt; từ malaysia tới tp hcm</td>\n",
              "      <td>Ngày 6/3 anh này đi chuyến AK1502 từ Malaysia tới TP HCM</td>\n",
              "      <td>[O, B-DATE, O, O, O, O, B-TRANSPORTATION, O, B-LOCATION, O, B-LOCATION, I-LOCATION]</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2123</th>\n",
              "      <td>ông là người thứ &lt;num&gt; ở vĩnh_phúc dương_tính ncov</td>\n",
              "      <td>Ông là người thứ 11 ở Vĩnh_Phúc dương_tính nCoV</td>\n",
              "      <td>[O, O, O, O, O, O, B-LOCATION, O, O]</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3458</th>\n",
              "      <td>bệnh_nhân điều_trị tại bệnh_viện bệnh nhiệt_đới trung_ương cơ_sở &lt;num&gt;</td>\n",
              "      <td>Bệnh_nhân điều_trị tại Bệnh_viện Bệnh nhiệt_đới Trung_ương cơ_sở 2</td>\n",
              "      <td>[O, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION]</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629</th>\n",
              "      <td>khi về đến phan_thiết bà còn di_chuyển đến nhiều nơi ăn_uống</td>\n",
              "      <td>Khi về đến Phan_Thiết bà còn di_chuyển đến nhiều nơi ăn_uống</td>\n",
              "      <td>[O, O, O, B-LOCATION, O, O, O, O, O, O, O]</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2766</th>\n",
              "      <td>ngày &lt;num&gt; - &lt;num&gt; bệnh_nhân được đưa đi cách_ly tập_trung tại quận &lt;num&gt;</td>\n",
              "      <td>Ngày 16 - 3 bệnh_nhân được đưa đi cách_ly tập_trung tại quận 8</td>\n",
              "      <td>[O, B-DATE, I-DATE, I-DATE, O, O, O, O, O, O, O, B-LOCATION, I-LOCATION]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2866</th>\n",
              "      <td>bệnh_viện đã chủ_động cách_ly bệnh_nhân và người tiếp_xúc gần tiến_hành khử khuẩn khu nhà_ăn</td>\n",
              "      <td>Bệnh_viện đã chủ_động cách_ly bệnh_nhân và người tiếp_xúc gần tiến_hành khử khuẩn khu nhà_ăn</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1417</th>\n",
              "      <td>đến &lt;num&gt;h&lt;num&gt; ngày &lt;num&gt;/&lt;num&gt; ông tử_vong</td>\n",
              "      <td>Đến 23h55 ngày 27/8 ông tử_vong</td>\n",
              "      <td>[O, O, O, B-DATE, O, O]</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5023</th>\n",
              "      <td>mẫu lần hai ngày &lt;num&gt;/&lt;num&gt; kết_quả sàng_lọc dương_tính</td>\n",
              "      <td>Mẫu lần hai ngày 22/7 kết_quả sàng_lọc dương_tính</td>\n",
              "      <td>[O, O, O, O, B-DATE, O, O, O]</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3373</th>\n",
              "      <td>bệnh_nhân có tiếp_xúc với bệnh_nhân dương_tính tại mỹ ngày &lt;num&gt;/&lt;num&gt;</td>\n",
              "      <td>Bệnh_nhân có tiếp_xúc với bệnh_nhân dương_tính tại Mỹ ngày 8/3</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-LOCATION, O, B-DATE]</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1355</th>\n",
              "      <td>riêng các trường_hợp tiếp_xúc gần với bệnh_nhân &lt;num&gt; được xác_định lên tới &lt;num&gt; ca</td>\n",
              "      <td>Riêng các trường_hợp tiếp_xúc gần với bệnh_nhân 34 được xác_định lên tới 46 ca</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-PATIENT_ID, O, O, O, O, O, O]</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3952</th>\n",
              "      <td>theo đó các bệnh_nhân ra viên gồm bệnh_nhân &lt;num&gt; &lt;num&gt; và &lt;num&gt;</td>\n",
              "      <td>Theo đó các bệnh_nhân ra viên gồm bệnh_nhân 22 23 và 35</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-PATIENT_ID, B-PATIENT_ID, O, B-PATIENT_ID]</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>ngày &lt;num&gt;/&lt;num&gt; ông bố bị sốt ba ngày sau đến lượt con trai sốt</td>\n",
              "      <td>Ngày 17/1 ông bố bị sốt ba ngày sau đến lượt con trai sốt</td>\n",
              "      <td>[O, B-DATE, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4701</th>\n",
              "      <td>biểu_hiện bệnh của bệnh_nhân cũng không có triệu_chứng nên vẫn xuất_cảnh được bình_thường</td>\n",
              "      <td>Biểu_hiện bệnh của bệnh_nhân cũng không có triệu_chứng nên vẫn xuất_cảnh được bình_thường</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d97e78c-f877-47fb-8fac-95ebc8f3e6c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d97e78c-f877-47fb-8fac-95ebc8f3e6c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d97e78c-f877-47fb-8fac-95ebc8f3e6c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                      word_process  \\\n",
              "idx                                                                                                  \n",
              "1966  tại hà_nội bệnh_nhân đi làm và gặp_gỡ bạn_bè tại nhiều nơi                                     \n",
              "4004  trước đó ngày <num>/<num> nữ doanh_nhân đi từ việt_nam sang mỹ có quá_cảnh hàn_quốc            \n",
              "3010  ngày <num>/<num> bệnh_nhân ra hà_nội                                                           \n",
              "403   chồng của bà đã tử_vong do covid - <num> và suy thận mạn                                       \n",
              "913   bé trai <num> tuổi được ra viện sáng nay ngụ phường cát_lái quận <num>                         \n",
              "845   cô từ mỹ_về quá_cảnh ở philippines nhập_cảnh việt_nam ngày <num> - <num>                       \n",
              "958   theo đó ca bệnh <num> bệnh_nhân <num> là nam <num> tuổi tân_bình thành_phố hải_dương           \n",
              "3420  ngày <num>/<num> anh này đi chuyến ak<num> từ malaysia tới tp hcm                              \n",
              "2123  ông là người thứ <num> ở vĩnh_phúc dương_tính ncov                                             \n",
              "3458  bệnh_nhân điều_trị tại bệnh_viện bệnh nhiệt_đới trung_ương cơ_sở <num>                         \n",
              "2629  khi về đến phan_thiết bà còn di_chuyển đến nhiều nơi ăn_uống                                   \n",
              "2766  ngày <num> - <num> bệnh_nhân được đưa đi cách_ly tập_trung tại quận <num>                      \n",
              "2866  bệnh_viện đã chủ_động cách_ly bệnh_nhân và người tiếp_xúc gần tiến_hành khử khuẩn khu nhà_ăn   \n",
              "1417  đến <num>h<num> ngày <num>/<num> ông tử_vong                                                   \n",
              "5023  mẫu lần hai ngày <num>/<num> kết_quả sàng_lọc dương_tính                                       \n",
              "3373  bệnh_nhân có tiếp_xúc với bệnh_nhân dương_tính tại mỹ ngày <num>/<num>                         \n",
              "1355  riêng các trường_hợp tiếp_xúc gần với bệnh_nhân <num> được xác_định lên tới <num> ca           \n",
              "3952  theo đó các bệnh_nhân ra viên gồm bệnh_nhân <num> <num> và <num>                               \n",
              "110   ngày <num>/<num> ông bố bị sốt ba ngày sau đến lượt con trai sốt                               \n",
              "4701  biểu_hiện bệnh của bệnh_nhân cũng không có triệu_chứng nên vẫn xuất_cảnh được bình_thường      \n",
              "\n",
              "                                                                                              word  \\\n",
              "idx                                                                                                  \n",
              "1966  Tại Hà_Nội bệnh_nhân đi làm và gặp_gỡ bạn_bè tại nhiều nơi                                     \n",
              "4004  Trước đó ngày 22/2 nữ doanh_nhân đi từ Việt_Nam sang Mỹ có quá_cảnh Hàn_Quốc                   \n",
              "3010  Ngày 25/7 bệnh_nhân ra Hà_Nội                                                                  \n",
              "403   Chồng của bà đã tử_vong do Covid - 19 và suy thận mạn                                          \n",
              "913   Bé trai 10 tuổi được ra viện sáng nay ngụ phường Cát_Lái quận 2                                \n",
              "845   Cô từ Mỹ_về quá_cảnh ở Philippines nhập_cảnh Việt_Nam ngày 13 - 3                              \n",
              "958   Theo đó ca bệnh 963 bệnh_nhân 963 là nam 30 tuổi Tân_Bình thành_phố Hải_Dương                  \n",
              "3420  Ngày 6/3 anh này đi chuyến AK1502 từ Malaysia tới TP HCM                                       \n",
              "2123  Ông là người thứ 11 ở Vĩnh_Phúc dương_tính nCoV                                                \n",
              "3458  Bệnh_nhân điều_trị tại Bệnh_viện Bệnh nhiệt_đới Trung_ương cơ_sở 2                             \n",
              "2629  Khi về đến Phan_Thiết bà còn di_chuyển đến nhiều nơi ăn_uống                                   \n",
              "2766  Ngày 16 - 3 bệnh_nhân được đưa đi cách_ly tập_trung tại quận 8                                 \n",
              "2866  Bệnh_viện đã chủ_động cách_ly bệnh_nhân và người tiếp_xúc gần tiến_hành khử khuẩn khu nhà_ăn   \n",
              "1417  Đến 23h55 ngày 27/8 ông tử_vong                                                                \n",
              "5023  Mẫu lần hai ngày 22/7 kết_quả sàng_lọc dương_tính                                              \n",
              "3373  Bệnh_nhân có tiếp_xúc với bệnh_nhân dương_tính tại Mỹ ngày 8/3                                 \n",
              "1355  Riêng các trường_hợp tiếp_xúc gần với bệnh_nhân 34 được xác_định lên tới 46 ca                 \n",
              "3952  Theo đó các bệnh_nhân ra viên gồm bệnh_nhân 22 23 và 35                                        \n",
              "110   Ngày 17/1 ông bố bị sốt ba ngày sau đến lượt con trai sốt                                      \n",
              "4701  Biểu_hiện bệnh của bệnh_nhân cũng không có triệu_chứng nên vẫn xuất_cảnh được bình_thường      \n",
              "\n",
              "                                                                                                         tag  \\\n",
              "idx                                                                                                            \n",
              "1966  [O, B-LOCATION, O, O, O, O, O, O, O, O, O]                                                               \n",
              "4004  [O, O, O, B-DATE, O, O, O, O, B-LOCATION, O, B-LOCATION, O, O, B-LOCATION]                               \n",
              "3010  [O, B-DATE, O, O, B-LOCATION]                                                                            \n",
              "403   [O, O, O, O, O, O, O, O, O, O, B-SYMPTOM_AND_DISEASE, I-SYMPTOM_AND_DISEASE, I-SYMPTOM_AND_DISEASE]      \n",
              "913   [O, O, O, O, O, O, O, O, O, O, B-LOCATION, I-LOCATION, B-LOCATION, I-LOCATION]                           \n",
              "845   [O, O, B-LOCATION, O, O, B-LOCATION, O, B-LOCATION, O, B-DATE, I-DATE, I-DATE]                           \n",
              "958   [O, O, O, O, B-PATIENT_ID, O, B-PATIENT_ID, O, B-GENDER, B-AGE, O, B-LOCATION, B-LOCATION, I-LOCATION]   \n",
              "3420  [O, B-DATE, O, O, O, O, B-TRANSPORTATION, O, B-LOCATION, O, B-LOCATION, I-LOCATION]                      \n",
              "2123  [O, O, O, O, O, O, B-LOCATION, O, O]                                                                     \n",
              "3458  [O, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION]                        \n",
              "2629  [O, O, O, B-LOCATION, O, O, O, O, O, O, O]                                                               \n",
              "2766  [O, B-DATE, I-DATE, I-DATE, O, O, O, O, O, O, O, B-LOCATION, I-LOCATION]                                 \n",
              "2866  [O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                               \n",
              "1417  [O, O, O, B-DATE, O, O]                                                                                  \n",
              "5023  [O, O, O, O, B-DATE, O, O, O]                                                                            \n",
              "3373  [O, O, O, O, O, O, O, B-LOCATION, O, B-DATE]                                                             \n",
              "1355  [O, O, O, O, O, O, O, B-PATIENT_ID, O, O, O, O, O, O]                                                    \n",
              "3952  [O, O, O, O, O, O, O, O, B-PATIENT_ID, B-PATIENT_ID, O, B-PATIENT_ID]                                    \n",
              "110   [O, B-DATE, O, O, O, O, O, O, O, O, O, O, O, O]                                                          \n",
              "4701  [O, O, O, O, O, O, O, O, O, O, O, O, O]                                                                  \n",
              "\n",
              "      len_tag  \n",
              "idx            \n",
              "1966  11       \n",
              "4004  14       \n",
              "3010  5        \n",
              "403   13       \n",
              "913   14       \n",
              "845   12       \n",
              "958   14       \n",
              "3420  12       \n",
              "2123  9        \n",
              "3458  9        \n",
              "2629  11       \n",
              "2766  13       \n",
              "2866  14       \n",
              "1417  6        \n",
              "5023  8        \n",
              "3373  10       \n",
              "1355  14       \n",
              "3952  12       \n",
              "110   14       \n",
              "4701  13       "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_train_data_group[word_train_data_group['len_tag'] < 15].sample(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItK-M8iLuiZG"
      },
      "source": [
        "#CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIKRa5zLuhxQ"
      },
      "outputs": [],
      "source": [
        "class CRF(L.Layer):\n",
        "    def __init__(self,\n",
        "                 output_dim,\n",
        "                 sparse_target=True,\n",
        "                 **kwargs):\n",
        "        \"\"\"    \n",
        "        Args:\n",
        "            output_dim (int): the number of labels to tag each temporal input.\n",
        "            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n",
        "        Input shape:\n",
        "            (batch_size, sentence length, output_dim)\n",
        "        Output shape:\n",
        "            (batch_size, sentence length, output_dim)\n",
        "        \"\"\"\n",
        "        super(CRF, self).__init__(**kwargs)\n",
        "        self.output_dim = int(output_dim) \n",
        "        self.sparse_target = sparse_target\n",
        "        self.input_spec = L.InputSpec(min_ndim=3)\n",
        "        self.supports_masking = False\n",
        "        self.sequence_lengths = None\n",
        "        self.transitions = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "        f_shape = tf.TensorShape(input_shape)\n",
        "        input_spec = L.InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n",
        "\n",
        "        if f_shape[-1] is None:\n",
        "            raise ValueError('The last dimension of the inputs to `CRF` '\n",
        "                             'should be defined. Found `None`.')\n",
        "        if f_shape[-1] != self.output_dim:\n",
        "            raise ValueError('The last dimension of the input shape must be equal to output'\n",
        "                             ' shape. Use a linear layer if needed.')\n",
        "        self.input_spec = input_spec\n",
        "        self.transitions = self.add_weight(name='transitions',\n",
        "                                           shape=[self.output_dim, self.output_dim],\n",
        "                                           initializer='glorot_uniform',\n",
        "                                           trainable=True)\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Just pass the received mask from previous layer, to the next layer or\n",
        "        # manipulate it if this layer changes the shape of the input\n",
        "        return mask\n",
        "\n",
        "    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n",
        "        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n",
        "        if sequence_lengths is not None:\n",
        "            assert len(sequence_lengths.shape) == 2\n",
        "            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n",
        "            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n",
        "            assert seq_len_shape[1] == 1\n",
        "            self.sequence_lengths = K.flatten(sequence_lengths)\n",
        "        else:\n",
        "            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n",
        "                tf.shape(inputs)[1]\n",
        "            )\n",
        "\n",
        "        viterbi_sequence, _ = crf_decode(sequences,\n",
        "                                         self.transitions,\n",
        "                                         self.sequence_lengths)\n",
        "        output = K.one_hot(viterbi_sequence, self.output_dim)\n",
        "        return K.in_train_phase(sequences, output)\n",
        "\n",
        "    @property\n",
        "    def loss(self):\n",
        "        def crf_loss(y_true, y_pred):\n",
        "            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
        "            log_likelihood, self.transitions = crf_log_likelihood(\n",
        "                y_pred,\n",
        "                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
        "                self.sequence_lengths,\n",
        "                transition_params=self.transitions,\n",
        "            )\n",
        "            return tf.reduce_mean(-log_likelihood)\n",
        "        return crf_loss\n",
        "\n",
        "    @property\n",
        "    def accuracy(self):\n",
        "        def viterbi_accuracy(y_true, y_pred):\n",
        "            # -1e10 to avoid zero at sum(mask)\n",
        "            mask = K.cast(\n",
        "                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
        "            shape = tf.shape(y_pred)\n",
        "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
        "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
        "            if self.sparse_target:\n",
        "                y_true = K.argmax(y_true, 2)\n",
        "            y_pred = K.cast(y_pred, 'int32')\n",
        "            y_true = K.cast(y_true, 'int32')\n",
        "            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
        "            return K.sum(corrects * mask) / K.sum(mask)\n",
        "        return viterbi_accuracy\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        tf.TensorShape(input_shape).assert_has_rank(3)\n",
        "        return input_shape[:2] + (self.output_dim,)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'output_dim': self.output_dim,\n",
        "            'sparse_target': self.sparse_target,\n",
        "            'supports_masking': self.supports_masking,\n",
        "            'transitions': K.eval(self.transitions)\n",
        "        }\n",
        "        base_config = super(CRF, self).get_config()\n",
        "        return dict(base_config, **config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDy9K8TiXoFi"
      },
      "source": [
        "# FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjtK4XxMXQsu"
      },
      "outputs": [],
      "source": [
        "word_trained = False\n",
        "syll_trained = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPPAue7MhI0e"
      },
      "outputs": [],
      "source": [
        "def train_model_fasttext(train_data, size=100, window=5, min_count=3, negative=5, sg=1, alpha=0.01, epoch=50):\n",
        "    train_data = [each.split() for each in train_data]\n",
        "    model_fasttext = FastText(vector_size=size, window=window, min_count=min_count, \n",
        "                              workers=4, sg=1, negative=negative, alpha=alpha)\n",
        "    model_fasttext.build_vocab(train_data)\n",
        "    model_fasttext.train(train_data, total_examples=model_fasttext.corpus_count, epochs=epoch)\n",
        "    return model_fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Stxhegaaegt8"
      },
      "outputs": [],
      "source": [
        "if word_trained:\n",
        "    word_md = FastText.load('word_model_fasttext_gensim.bin')\n",
        "else:\n",
        "    word_md = train_model_fasttext([*word_train_data_group['word_process'], \n",
        "                                    *word_val_data_group['word_process']], \n",
        "                                    epoch=50, window=5)\n",
        "    word_md.save('word_model_fasttext_gensim.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiQBaFuzI-X9"
      },
      "outputs": [],
      "source": [
        "word_tokenizer = Tokenizer(num_words=len(word_md.wv.key_to_index), lower=True, filters=\"\", oov_token='-OOV-')\n",
        "word_tokenizer.fit_on_texts([*word_train_data_group['word_process'], *word_val_data_group['word_process']])\n",
        "word_index = word_tokenizer.word_index\n",
        "emb_mean, emb_std = -0.5,0.5\n",
        "embed_size = 100  \n",
        "nb_words = len(word_index) + 1\n",
        "word_embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words: \n",
        "        continue\n",
        "    if word in word_md.wv.key_to_index:\n",
        "        word_embedding_matrix[i] = word_md.wv.get_vector(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlUnAUjjLAPs"
      },
      "outputs": [],
      "source": [
        "word_max_length = 60\n",
        "word_X_train = word_tokenizer.texts_to_sequences(word_train_data_group['word_process'])\n",
        "word_X_val = word_tokenizer.texts_to_sequences(word_val_data_group['word_process'])\n",
        "word_X_test = word_tokenizer.texts_to_sequences(word_test_data_group['word_process'])\n",
        "\n",
        "word_X_train = pad_sequences(word_X_train, maxlen=word_max_length, padding='post')\n",
        "word_X_val = pad_sequences(word_X_val, maxlen=word_max_length, padding='post')\n",
        "word_X_test = pad_sequences(word_X_test, maxlen=word_max_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj_kbJH0L-6Z"
      },
      "outputs": [],
      "source": [
        "word_tag_tokenizer = Tokenizer(filters=\"\", lower=False)\n",
        "word_tag_tokenizer.fit_on_texts(word_train_data_group['tag'].apply(lambda x: ' '.join(x)))\n",
        "word_tag_index = word_tag_tokenizer.word_index\n",
        "word_tag_size = len(word_tag_index)+1\n",
        "\n",
        "word_y_train = word_tag_tokenizer.texts_to_sequences(word_train_data_group['tag'].apply(lambda x: ' '.join(x)))\n",
        "word_y_val = word_tag_tokenizer.texts_to_sequences(word_val_data_group['tag'].apply(lambda x: ' '.join(x)))\n",
        "word_y_test = word_tag_tokenizer.texts_to_sequences(word_test_data_group['tag'].apply(lambda x: ' '.join(x)))\n",
        "\n",
        "word_y_train = pad_sequences(word_y_train, maxlen=word_max_length, padding='post')\n",
        "word_y_val = pad_sequences(word_y_val, maxlen=word_max_length, padding='post')\n",
        "word_y_test = pad_sequences(word_y_test, maxlen=word_max_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUDYx-ylP7Mc"
      },
      "outputs": [],
      "source": [
        "word_y_train = np.asarray([to_categorical(i, num_classes=word_tag_size) for i in word_y_train])\n",
        "word_y_val = np.asarray([to_categorical(i, num_classes=word_tag_size) for i in word_y_val])\n",
        "word_y_test = np.asarray([to_categorical(i, num_classes=word_tag_size) for i in word_y_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x003rxWDK-tm"
      },
      "source": [
        "#MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKWWYXQXBbVQ"
      },
      "source": [
        "## Without CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mev2zNb6bL46"
      },
      "outputs": [],
      "source": [
        "def create_model(embeddings_matrix, vocab_size, embedding_dim, max_length):\n",
        "    input = Input(shape = (max_length, ), dtype='int32', name='input_text')\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim, \n",
        "                  weights=[word_embedding_matrix])(input)\n",
        "    x = Bidirectional(LSTM(units=max_length, return_sequences=True, \n",
        "                                recurrent_dropout=0.01))(x)                        \n",
        "    x = TimeDistributed(Dense(128, activation='relu', kernel_initializer='he_normal'))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.5)(x) \n",
        "    output = Dense(word_tag_size, activation='softmax', kernel_initializer='he_normal')(x)\n",
        "    model_final = Model(input, output)\n",
        "    model_final.compile(optimizer=Optimizer.Adam(lr=0.005), loss='categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "    return model_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjf56fmOBe1x",
        "outputId": "a596a268-20e8-411d-fdcc-d7a4b5999d3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_text (InputLayer)     [(None, 60)]              0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 60, 100)           451700    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 60, 120)          77280     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 60, 128)          15488     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 60, 128)          512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 60, 128)           0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 60, 21)            2709      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 547,689\n",
            "Trainable params: 547,433\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = create_model(word_embedding_matrix, nb_words, embed_size, word_max_length)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZocSoblnBe1z",
        "outputId": "34d462ef-f26c-4b9a-fd8f-8189ccc8527e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 38s 423ms/step - loss: 0.3274 - accuracy: 0.9184 - val_loss: 0.2778 - val_accuracy: 0.9215\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 35s 440ms/step - loss: 0.0750 - accuracy: 0.9779 - val_loss: 0.1517 - val_accuracy: 0.9633\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 34s 425ms/step - loss: 0.0500 - accuracy: 0.9852 - val_loss: 0.0889 - val_accuracy: 0.9763\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 34s 426ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.0851 - val_accuracy: 0.9765\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 33s 417ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.0777 - val_accuracy: 0.9796\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 33s 420ms/step - loss: 0.0264 - accuracy: 0.9923 - val_loss: 0.0827 - val_accuracy: 0.9796\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 33s 418ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0739 - val_accuracy: 0.9822\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 33s 416ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0746 - val_accuracy: 0.9831\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 34s 433ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 0.0696 - val_accuracy: 0.9835\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 33s 415ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.0726 - val_accuracy: 0.9840\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9fe43dc1c0>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(word_X_train, word_y_train, batch_size=64, epochs=10, validation_data = (word_X_val, word_y_val), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eV2raUUBe1z"
      },
      "outputs": [],
      "source": [
        "def get_tags(sequences, tag_index):\n",
        "    sequence_tags = []\n",
        "    for sequence in sequences:\n",
        "        sequence_tag = []\n",
        "        for categorical in sequence:\n",
        "            sequence_tag.append(tag_index.get(np.argmax(categorical)))\n",
        "        sequence_tags.append(sequence_tag)\n",
        "    return sequence_tags\n",
        "\n",
        "def predict(model, tag_tokenizer, sent):\n",
        "    tag_index = tag_tokenizer.word_index\n",
        "    tag_size = len(tag_index) + 1\n",
        "    pred = model.predict(sent)\n",
        "    sequence_tags = get_tags(pred, {i: t for t, i in tag_index.items()})\n",
        "    for idx, each in enumerate(sequence_tags):\n",
        "        try:\n",
        "           idx_cut = each.index(None)\n",
        "        except:\n",
        "           idx_cut = len(each) + 1\n",
        "        sequence_tags[idx] = each[:idx_cut]\n",
        "    return sequence_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lWpy9c9Be10",
        "outputId": "0fb987cd-abc5-4c07-bfb4-7308a42a598c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 4s 36ms/step\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE       0.86      0.90      0.88       572\n",
            "               DATE       0.95      0.95      0.95      1644\n",
            "             GENDER       0.87      0.87      0.87       453\n",
            "                JOB       0.48      0.53      0.50       173\n",
            "           LOCATION       0.81      0.84      0.83      4413\n",
            "               NAME       0.74      0.70      0.72       314\n",
            "       ORGANIZATION       0.72      0.70      0.71       769\n",
            "         PATIENT_ID       0.94      0.93      0.93      1976\n",
            "SYMPTOM_AND_DISEASE       0.68      0.68      0.68      1128\n",
            "     TRANSPORTATION       0.90      0.88      0.89       193\n",
            "\n",
            "          micro avg       0.83      0.84      0.84     11635\n",
            "          macro avg       0.80      0.80      0.80     11635\n",
            "       weighted avg       0.83      0.84      0.84     11635\n",
            "\n"
          ]
        }
      ],
      "source": [
        "res = predict(model, word_tag_tokenizer, word_X_test)\n",
        "print(classification_report(word_test_data_group['tag'].apply(lambda x: x[:word_max_length]), res))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PE2NdqK5TG-"
      },
      "source": [
        "## With CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdZ48UTM5HQl"
      },
      "outputs": [],
      "source": [
        "def create_model_crf(embeddings_matrix, vocab_size, embedding_dim, max_length):\n",
        "    input = Input(shape = (max_length, ), dtype='int32', name='input_text')\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim, \n",
        "                  weights=[word_embedding_matrix])(input)\n",
        "    x = Bidirectional(LSTM(units=max_length, return_sequences=True, \n",
        "                                recurrent_dropout=0.01))(x)                        \n",
        "    x = TimeDistributed(Dense(128, activation='relu', kernel_initializer='he_normal'))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.5)(x) \n",
        "    x = Dense(word_tag_size, activation='relu', kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.1)(x)   \n",
        "    crf = CRF(word_tag_size)\n",
        "    output = crf(x)\n",
        "    model_final = Model(input, output)\n",
        "    model_final.compile(optimizer=Optimizer.Adam(lr=0.005), loss=crf.loss,\n",
        "                        metrics=[crf.accuracy])\n",
        "\n",
        "    return model_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFgLImwSfvLt",
        "outputId": "7bb3ab11-4d12-4359-d327-703e7881fc4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_text (InputLayer)     [(None, 60)]              0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 60, 100)           451700    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 60, 120)          77280     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 60, 128)          15488     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 60, 128)          512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 60, 128)           0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 60, 21)            2709      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 60, 21)           84        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 60, 21)            0         \n",
            "                                                                 \n",
            " crf (CRF)                   (None, 60, 21)            441       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 548,214\n",
            "Trainable params: 547,916\n",
            "Non-trainable params: 298\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = create_model_crf(word_embedding_matrix, nb_words, embed_size, word_max_length)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlSyWhtUJfpT",
        "outputId": "8ba095b2-3f75-42f9-8c7c-d8ece2cad93a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 57s 586ms/step - loss: 98.6042 - viterbi_accuracy: 0.7059 - val_loss: 104.9873 - val_viterbi_accuracy: 0.9095\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 46s 580ms/step - loss: 30.5124 - viterbi_accuracy: 0.9715 - val_loss: 79.2038 - val_viterbi_accuracy: 0.9248\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 12.7847 - viterbi_accuracy: 0.9783 - val_loss: 65.7644 - val_viterbi_accuracy: 0.9314\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 44s 564ms/step - loss: 7.9843 - viterbi_accuracy: 0.9818 - val_loss: 56.8827 - val_viterbi_accuracy: 0.9335\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 5.7889 - viterbi_accuracy: 0.9847 - val_loss: 50.7504 - val_viterbi_accuracy: 0.9361\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 46s 582ms/step - loss: 4.6077 - viterbi_accuracy: 0.9866 - val_loss: 46.5521 - val_viterbi_accuracy: 0.9348\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 44s 559ms/step - loss: 3.6381 - viterbi_accuracy: 0.9891 - val_loss: 42.9807 - val_viterbi_accuracy: 0.9364\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 44s 554ms/step - loss: 3.0927 - viterbi_accuracy: 0.9904 - val_loss: 40.1605 - val_viterbi_accuracy: 0.9359\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 44s 559ms/step - loss: 2.5132 - viterbi_accuracy: 0.9920 - val_loss: 37.6219 - val_viterbi_accuracy: 0.9361\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 44s 554ms/step - loss: 2.1969 - viterbi_accuracy: 0.9929 - val_loss: 35.4918 - val_viterbi_accuracy: 0.9362\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa067a59520>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(word_X_train, word_y_train, batch_size=64, epochs=10, validation_data = (word_X_val, word_y_val), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc7rRHC82rO_"
      },
      "outputs": [],
      "source": [
        "def get_tags(sequences, tag_index):\n",
        "    sequence_tags = []\n",
        "    for sequence in sequences:\n",
        "        sequence_tag = []\n",
        "        for categorical in sequence:\n",
        "            sequence_tag.append(tag_index.get(np.argmax(categorical)))\n",
        "        sequence_tags.append(sequence_tag)\n",
        "    return sequence_tags\n",
        "\n",
        "def predict(model, tag_tokenizer, sent):\n",
        "    tag_index = tag_tokenizer.word_index\n",
        "    tag_size = len(tag_index) + 1\n",
        "    pred = model.predict(sent)\n",
        "    sequence_tags = get_tags(pred, {i: t for t, i in tag_index.items()})\n",
        "    for idx, each in enumerate(sequence_tags):\n",
        "        try:\n",
        "           idx_cut = each.index(None)\n",
        "        except:\n",
        "           idx_cut = len(each) + 1\n",
        "        sequence_tags[idx] = each[:idx_cut]\n",
        "    return sequence_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2s2jLFQ-FFL",
        "outputId": "8a647b21-e3c7-46b4-b51e-10f30b425df1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE       0.91      0.88      0.90       572\n",
            "               DATE       0.97      0.96      0.96      1644\n",
            "             GENDER       0.90      0.88      0.89       453\n",
            "                JOB       0.67      0.36      0.47       173\n",
            "           LOCATION       0.87      0.85      0.86      4413\n",
            "               NAME       0.89      0.59      0.71       314\n",
            "       ORGANIZATION       0.86      0.73      0.79       769\n",
            "         PATIENT_ID       0.94      0.93      0.93      1976\n",
            "SYMPTOM_AND_DISEASE       0.79      0.66      0.72      1128\n",
            "     TRANSPORTATION       0.97      0.81      0.88       193\n",
            "\n",
            "          micro avg       0.89      0.84      0.86     11635\n",
            "          macro avg       0.88      0.77      0.81     11635\n",
            "       weighted avg       0.89      0.84      0.86     11635\n",
            "\n"
          ]
        }
      ],
      "source": [
        "res = predict(model, word_tag_tokenizer, word_X_test)\n",
        "print(classification_report(word_test_data_group['tag'].apply(lambda x: x[:word_max_length]), res))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}