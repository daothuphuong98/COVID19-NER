{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b9e503bd178f43e1ad5eac49ecfdfee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3990774a689494296fb85faae26d13f",
              "IPY_MODEL_a78ebbc20aaa4142b5f120d47ba8c893",
              "IPY_MODEL_e6cd6b73362841558f20d8addb219ea2"
            ],
            "layout": "IPY_MODEL_5435290e23f248989eb7a7269d30d605"
          }
        },
        "f3990774a689494296fb85faae26d13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2674ef1a72844012917176fb95cdf9e3",
            "placeholder": "​",
            "style": "IPY_MODEL_74afe5822719440fb7bfb454dc808973",
            "value": "Downloading: 100%"
          }
        },
        "a78ebbc20aaa4142b5f120d47ba8c893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43e4fecf62f64de58d837febc13cb5b2",
            "max": 1115590446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e602944508574965a6f84505d69f84a4",
            "value": 1115590446
          }
        },
        "e6cd6b73362841558f20d8addb219ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0fc26ecbcc74939a18a8125bd096ea9",
            "placeholder": "​",
            "style": "IPY_MODEL_1169359788ec4f8e8972a9fa29a70f23",
            "value": " 1.12G/1.12G [00:21&lt;00:00, 68.5MB/s]"
          }
        },
        "5435290e23f248989eb7a7269d30d605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2674ef1a72844012917176fb95cdf9e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74afe5822719440fb7bfb454dc808973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43e4fecf62f64de58d837febc13cb5b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e602944508574965a6f84505d69f84a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0fc26ecbcc74939a18a8125bd096ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1169359788ec4f8e8972a9fa29a70f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daothuphuong98/COVID19-NER/blob/main/XLMR_BASE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8DfXHY8xrBRI",
        "outputId": "e85fba30-e868-43bb-ca8f-cc03a5e8ae31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/VinAIResearch/PhoNER_COVID19.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq9beqYrBWSH",
        "outputId": "7b3d6d26-f93b-4f4a-d090-81b24c3f0be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PhoNER_COVID19'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 58 (delta 23), reused 41 (delta 18), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (58/58), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets pytorch-crf==0.7.2 seqeval transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX-NSlpCu6kA",
        "outputId": "65ee5dbb-681e-4fb3-8cba-47099e791973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[K     |████████████████████████████████| 452 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting pytorch-crf==0.7.2\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 25.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 56.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 50.8 MB/s \n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 82.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 73.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 71.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=4a8ca8a9da563a839645d32dc1dabfcf6bd71304934ad8e5d44c6f347c105523\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built seqeval\n",
            "Installing collected packages: urllib3, xxhash, tokenizers, responses, multiprocess, huggingface-hub, transformers, seqeval, pytorch-crf, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.8.0 huggingface-hub-0.11.1 multiprocess-0.70.14 pytorch-crf-0.7.2 responses-0.18.0 seqeval-1.2.2 tokenizers-0.13.2 transformers-4.25.1 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import BertForTokenClassification, AdamW, XLMRobertaTokenizer, XLMRobertaConfig, XLMRobertaModel, TrainingArguments, AutoTokenizer, AutoConfig, Trainer, AutoModel, DataCollatorForTokenClassification\n",
        "from tqdm import tqdm, trange, tqdm_notebook\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
        "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
        "from seqeval.metrics import f1_score, classification_report\n",
        "from datasets import ClassLabel, Dataset, DatasetDict\n",
        "# from transformers import get_linear_schedule_with_warmup, get_constant_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "metadata": {
        "id": "CLNMGG8lvEze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f11683d-5a72-4e99-bc1e-60e6aea39922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f82015fadac9>:17: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  pd.set_option('display.max_colwidth', -1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(device)\n",
        "\n",
        "MAX_LEN = 256\n",
        "BS = 32\n",
        "\n",
        "linear_dropout = 0.3\n",
        "bert_att_dropout = 0.15\n",
        "bert_hidd_dropout = 0.2\n",
        "\n",
        "bert_lr = 1e-5\n",
        "bert_weight_decay = 1e-5\n",
        "softmax_lr = 1e-3\n",
        "softmax_weight_decay = 1e-3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGFNpbxexjoz",
        "outputId": "48e4b4ec-5db1-4fed-f253-0625717e98c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDIqpTg7-6pb",
        "outputId": "55dd5a3f-b71e-492f-b503-46bf80a9ea46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 20 11:23:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    31W /  70W |      3MiB / 15109MiB |      5%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data"
      ],
      "metadata": {
        "id": "QaW8nEUyQitV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_file(link):\n",
        "    with open(link) as f:\n",
        "        contents = f.readlines()\n",
        "    idx_sentence, idx_arr, word, tag = 0, [], [], []\n",
        "    for line in contents:\n",
        "        arr_info = line.split(' ')\n",
        "        # print(arr_info)\n",
        "        if len(arr_info) == 1:\n",
        "            idx_sentence += 1\n",
        "            continue\n",
        "        word.append(arr_info[0])\n",
        "        tag.append(arr_info[1].replace('\\n', ''))\n",
        "        idx_arr.append(idx_sentence)\n",
        "    return pd.DataFrame(\n",
        "        data = {\n",
        "            'idx': idx_arr,\n",
        "            'word': word,\n",
        "            'tag': tag\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "id": "LO5gHyUfQhyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_train_data = handle_file('/content/PhoNER_COVID19/data/word/train_word.conll')\n",
        "word_test_data = handle_file('/content/PhoNER_COVID19/data/word/test_word.conll')\n",
        "word_val_data = handle_file('/content/PhoNER_COVID19/data/word/dev_word.conll')\n",
        "\n",
        "word_train_data['word_process'] = word_train_data['word'].apply(lambda x: re.sub('[0-9]+', \"<NUM>\", x).lower())\n",
        "word_test_data['word_process'] = word_test_data['word'].apply(lambda x: re.sub('[0-9]+', \"<NUM>\", x).lower())\n",
        "word_val_data['word_process'] = word_val_data['word'].apply(lambda x: re.sub('[0-9]+', \"<NUM>\", x).lower())\n",
        "\n",
        "filter_string = '?!\"/\\{}().,'\n",
        "word_train_data = word_train_data[word_train_data['word_process'].apply(lambda x: x not in filter_string)]\n",
        "word_test_data = word_test_data[word_test_data['word_process'].apply(lambda x: x not in filter_string)]\n",
        "word_val_data = word_val_data[word_val_data['word_process'].apply(lambda x: x not in filter_string)]\n",
        "\n",
        "word_train_data_group = word_train_data.groupby('idx').agg({'word_process': ' '.join, 'word': ' '.join, 'tag': list}) \n",
        "word_test_data_group = word_test_data.groupby('idx').agg({'word_process': ' '.join, 'word': ' '.join, 'tag': list}) \n",
        "word_val_data_group = word_val_data.groupby('idx').agg({'word_process': ' '.join, 'word': ' '.join, 'tag': list}) \n",
        "\n",
        "word_train_data_group['len_tag'] = word_train_data_group['tag'].apply(lambda x: len(x))\n",
        "word_val_data_group['len_tag'] = word_val_data_group['tag'].apply(lambda x: len(x))\n",
        "word_test_data_group['len_tag'] = word_test_data_group['tag'].apply(lambda x: len(x))\n",
        "\n",
        "word_train_data_group['tag_string'] = word_train_data_group['tag'].apply(lambda x: ' '.join(x))\n",
        "word_val_data_group['tag_string'] = word_val_data_group['tag'].apply(lambda x: ' '.join(x))\n",
        "word_test_data_group['tag_string'] = word_test_data_group['tag'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# train_data_group = train_data_group[train_data_group['len_tag'] <= 55].reset_index()\n",
        "# val_data_group = val_data_group[val_data_group['len_tag'] <= 55].reset_index()\n",
        "# test_data_group = test_data_group[test_data_group['len_tag'] <= 55].reset_index()"
      ],
      "metadata": {
        "id": "zrybe1LBSyxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_train_data_group[word_train_data_group['len_tag'] < 15].sample(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4jG2m7Y4MAKN",
        "outputId": "9e77d4e5-de5a-492f-dbbb-c8fc7d54bcd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                              word_process  \\\n",
              "idx                                                                                                          \n",
              "161   kết_quả xét_nghiệm mẫu bệnh_phẩm dương_tính với ncov                                                   \n",
              "1579  hiện <num> bệnh_nhân được cách_ly điều_trị tại trung_tâm y_tế huyện cam_lâm khánh_hoà                  \n",
              "1258  ngày <num> đến <num> - <num> về nhà ông_bà ngoại ở thị_trấn nam_sách chơi                              \n",
              "3839  trung_tâm kiểm_soát bệnh_tật hà_nội lấy mẫu xét_nghiệm kết_quả bệnh_nhân dương_tính ncov               \n",
              "893   <num>h sáng ngày <num>/<num> bệnh_nhân được chuyển đến khoa y_học nhiệt_đới bệnh_viện đà_nẵng          \n",
              "2262  hiện bệnh_nhân điều_trị tại bệnh_viện dã_chiến củ_chi                                                  \n",
              "1535  bệnh_nhân <num> ở xã khải_xuân huyện thanh_ba tỉnh phú_thọ                                             \n",
              "4533  vài ngày trước khi có dấu_hiệu sốt bệnh_nhân cùng chồng đến chợ đầu_mối mua_sắm                        \n",
              "2955  đến thời_điểm này không có thêm nhân_viên y_tế nào của bạch_mai mắc bệnh                               \n",
              "3951  từ <num> đến <num> - <num> bệnh_nhân đi ôtô vào tp.hcm.                                                \n",
              "864   hiện bệnh_nhân có khó thở được đặt thở máy                                                             \n",
              "2661  bệnh_nhân thứ <num> là thanh_niên từ daegu hàn_quốc về nước ngày <num>/<num>                           \n",
              "4900  các bác_sĩ nhận_định bệnh_nhân <num> là một ca bệnh có tiền_sử dịch_tễ đặc_biệt                        \n",
              "346   ngày <num> - <num> bệnh_nhân cùng đoàn của bệnh_viện bạch_mai_công_tác tại tỉnh hà_nam                 \n",
              "2132  bệnh_nhân được hướng_dẫn tự cách_ly tại nhà                                                            \n",
              "4770  anh là một trong <num> người khác được xác_nhận nhiễm_bệnh hôm <num> - <num>                           \n",
              "321   ngày <num>/<num> bệnh_nhân thấy tức ngực mệt mẫu xét_nghiệm ngày <num>/<num> kết_quả dương_tính ncov   \n",
              "1507  quảng_nam là địa_phương ghi_nhận số bệnh_nhân nhiều thứ nhì sau đà_nẵng                                \n",
              "3878  hiện bệnh_nhân được cách_ly điều_trị tại bệnh_viện đa_khoa tỉnh bình_dương                             \n",
              "1805  bệnh_nhân là du_khách nhập_cảnh nội_bài ngày <num> - <num> trên chuyến bay su <num>                    \n",
              "\n",
              "                                                                                          word  \\\n",
              "idx                                                                                              \n",
              "161   Kết_quả xét_nghiệm mẫu bệnh_phẩm dương_tính với nCoV                                       \n",
              "1579  Hiện 2 bệnh_nhân được cách_ly điều_trị tại Trung_tâm Y_tế huyện Cam_Lâm Khánh_Hoà          \n",
              "1258  Ngày 6 đến 7 - 8 về nhà ông_bà ngoại ở thị_trấn Nam_Sách chơi                              \n",
              "3839  Trung_tâm Kiểm_soát bệnh_tật Hà_Nội lấy mẫu xét_nghiệm kết_quả bệnh_nhân dương_tính nCoV   \n",
              "893   2h sáng ngày 27/7 bệnh_nhân được chuyển đến khoa Y_học nhiệt_đới Bệnh_viện Đà_Nẵng         \n",
              "2262  Hiện bệnh_nhân điều_trị tại Bệnh_viện Dã_chiến Củ_Chi                                      \n",
              "1535  Bệnh_nhân 994 ở xã Khải_Xuân huyện Thanh_Ba tỉnh Phú_Thọ                                   \n",
              "4533  Vài ngày trước khi có dấu_hiệu sốt bệnh_nhân cùng chồng đến chợ đầu_mối mua_sắm            \n",
              "2955  Đến thời_điểm này không có thêm nhân_viên y_tế nào của Bạch_Mai mắc bệnh                   \n",
              "3951  Từ 27 đến 29 - 7 bệnh_nhân đi ôtô vào TP.HCM.                                              \n",
              "864   Hiện bệnh_nhân có khó thở được đặt thở máy                                                 \n",
              "2661  Bệnh_nhân thứ 18 là thanh_niên từ Daegu Hàn_Quốc về nước ngày 4/3                          \n",
              "4900  Các bác_sĩ nhận_định bệnh_nhân 268 là một ca bệnh có tiền_sử dịch_tễ đặc_biệt              \n",
              "346   Ngày 27 - 3 bệnh_nhân cùng đoàn của Bệnh_viện Bạch_Mai_công_tác tại tỉnh Hà_Nam            \n",
              "2132  Bệnh_nhân được hướng_dẫn tự cách_ly tại nhà                                                \n",
              "4770  Anh là một trong 3 người khác được xác_nhận nhiễm_bệnh hôm 13 - 2                          \n",
              "321   Ngày 9/7 bệnh_nhân thấy tức ngực mệt mẫu xét_nghiệm ngày 26/7 kết_quả dương_tính nCoV      \n",
              "1507  Quảng_Nam là địa_phương ghi_nhận số bệnh_nhân nhiều thứ nhì sau Đà_Nẵng                    \n",
              "3878  Hiện bệnh_nhân được cách_ly điều_trị tại Bệnh_viện Đa_khoa tỉnh Bình_Dương                 \n",
              "1805  Bệnh_nhân là du_khách nhập_cảnh Nội_Bài ngày 13 - 3 trên chuyến bay SU 290                 \n",
              "\n",
              "                                                                                                                   tag  \\\n",
              "idx                                                                                                                      \n",
              "161   [O, O, O, O, O, O, O]                                                                                              \n",
              "1579  [O, O, O, O, O, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, B-LOCATION]                                  \n",
              "1258  [O, B-DATE, O, B-DATE, I-DATE, I-DATE, O, O, O, O, O, B-LOCATION, I-LOCATION, O]                                   \n",
              "3839  [B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, O, O, O, O, O, O, O]                              \n",
              "893   [O, O, O, B-DATE, O, O, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION]                          \n",
              "2262  [O, O, O, O, B-LOCATION, I-LOCATION, I-LOCATION]                                                                   \n",
              "1535  [O, B-PATIENT_ID, O, B-LOCATION, I-LOCATION, B-LOCATION, I-LOCATION, B-LOCATION, I-LOCATION]                       \n",
              "4533  [O, O, O, O, O, O, B-SYMPTOM_AND_DISEASE, O, O, O, O, O, O, O]                                                     \n",
              "2955  [O, O, O, O, O, O, O, O, O, O, B-ORGANIZATION, O, O]                                                               \n",
              "3951  [O, B-DATE, O, B-DATE, I-DATE, I-DATE, O, O, O, O, B-LOCATION]                                                     \n",
              "864   [O, O, O, B-SYMPTOM_AND_DISEASE, I-SYMPTOM_AND_DISEASE, O, O, O, O]                                                \n",
              "2661  [O, O, B-PATIENT_ID, O, O, O, B-LOCATION, B-LOCATION, O, O, O, B-DATE]                                             \n",
              "4900  [O, O, O, O, B-PATIENT_ID, O, O, O, O, O, O, O, O]                                                                 \n",
              "346   [O, B-DATE, I-DATE, I-DATE, O, O, O, O, B-ORGANIZATION, I-ORGANIZATION, O, B-LOCATION, I-LOCATION]                 \n",
              "2132  [O, O, O, O, O, O, O]                                                                                              \n",
              "4770  [O, O, O, O, O, O, O, O, O, O, O, B-DATE, I-DATE, I-DATE]                                                          \n",
              "321   [O, B-DATE, O, O, B-SYMPTOM_AND_DISEASE, I-SYMPTOM_AND_DISEASE, B-SYMPTOM_AND_DISEASE, O, O, O, B-DATE, O, O, O]   \n",
              "1507  [B-LOCATION, O, O, O, O, O, O, O, O, O, B-LOCATION]                                                                \n",
              "3878  [O, O, O, O, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION]                                                 \n",
              "1805  [O, O, O, O, B-LOCATION, O, B-DATE, I-DATE, I-DATE, O, O, O, B-TRANSPORTATION, I-TRANSPORTATION]                   \n",
              "\n",
              "      len_tag  \\\n",
              "idx             \n",
              "161   7         \n",
              "1579  12        \n",
              "1258  14        \n",
              "3839  11        \n",
              "893   13        \n",
              "2262  7         \n",
              "1535  9         \n",
              "4533  14        \n",
              "2955  13        \n",
              "3951  11        \n",
              "864   9         \n",
              "2661  12        \n",
              "4900  13        \n",
              "346   13        \n",
              "2132  7         \n",
              "4770  14        \n",
              "321   14        \n",
              "1507  11        \n",
              "3878  10        \n",
              "1805  14        \n",
              "\n",
              "                                                                                             tag_string  \n",
              "idx                                                                                                      \n",
              "161   O O O O O O O                                                                                      \n",
              "1579  O O O O O O O B-LOCATION I-LOCATION I-LOCATION I-LOCATION B-LOCATION                               \n",
              "1258  O B-DATE O B-DATE I-DATE I-DATE O O O O O B-LOCATION I-LOCATION O                                  \n",
              "3839  B-ORGANIZATION I-ORGANIZATION I-ORGANIZATION I-ORGANIZATION O O O O O O O                          \n",
              "893   O O O B-DATE O O O O B-LOCATION I-LOCATION I-LOCATION I-LOCATION I-LOCATION                        \n",
              "2262  O O O O B-LOCATION I-LOCATION I-LOCATION                                                           \n",
              "1535  O B-PATIENT_ID O B-LOCATION I-LOCATION B-LOCATION I-LOCATION B-LOCATION I-LOCATION                 \n",
              "4533  O O O O O O B-SYMPTOM_AND_DISEASE O O O O O O O                                                    \n",
              "2955  O O O O O O O O O O B-ORGANIZATION O O                                                             \n",
              "3951  O B-DATE O B-DATE I-DATE I-DATE O O O O B-LOCATION                                                 \n",
              "864   O O O B-SYMPTOM_AND_DISEASE I-SYMPTOM_AND_DISEASE O O O O                                          \n",
              "2661  O O B-PATIENT_ID O O O B-LOCATION B-LOCATION O O O B-DATE                                          \n",
              "4900  O O O O B-PATIENT_ID O O O O O O O O                                                               \n",
              "346   O B-DATE I-DATE I-DATE O O O O B-ORGANIZATION I-ORGANIZATION O B-LOCATION I-LOCATION               \n",
              "2132  O O O O O O O                                                                                      \n",
              "4770  O O O O O O O O O O O B-DATE I-DATE I-DATE                                                         \n",
              "321   O B-DATE O O B-SYMPTOM_AND_DISEASE I-SYMPTOM_AND_DISEASE B-SYMPTOM_AND_DISEASE O O O B-DATE O O O  \n",
              "1507  B-LOCATION O O O O O O O O O B-LOCATION                                                            \n",
              "3878  O O O O O O B-LOCATION I-LOCATION I-LOCATION I-LOCATION                                            \n",
              "1805  O O O O B-LOCATION O B-DATE I-DATE I-DATE O O O B-TRANSPORTATION I-TRANSPORTATION                  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b6522a4-422d-4438-a5c1-363c597c86ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_process</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>len_tag</th>\n",
              "      <th>tag_string</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>idx</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>kết_quả xét_nghiệm mẫu bệnh_phẩm dương_tính với ncov</td>\n",
              "      <td>Kết_quả xét_nghiệm mẫu bệnh_phẩm dương_tính với nCoV</td>\n",
              "      <td>[O, O, O, O, O, O, O]</td>\n",
              "      <td>7</td>\n",
              "      <td>O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1579</th>\n",
              "      <td>hiện &lt;num&gt; bệnh_nhân được cách_ly điều_trị tại trung_tâm y_tế huyện cam_lâm khánh_hoà</td>\n",
              "      <td>Hiện 2 bệnh_nhân được cách_ly điều_trị tại Trung_tâm Y_tế huyện Cam_Lâm Khánh_Hoà</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, B-LOCATION]</td>\n",
              "      <td>12</td>\n",
              "      <td>O O O O O O O B-LOCATION I-LOCATION I-LOCATION I-LOCATION B-LOCATION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>ngày &lt;num&gt; đến &lt;num&gt; - &lt;num&gt; về nhà ông_bà ngoại ở thị_trấn nam_sách chơi</td>\n",
              "      <td>Ngày 6 đến 7 - 8 về nhà ông_bà ngoại ở thị_trấn Nam_Sách chơi</td>\n",
              "      <td>[O, B-DATE, O, B-DATE, I-DATE, I-DATE, O, O, O, O, O, B-LOCATION, I-LOCATION, O]</td>\n",
              "      <td>14</td>\n",
              "      <td>O B-DATE O B-DATE I-DATE I-DATE O O O O O B-LOCATION I-LOCATION O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3839</th>\n",
              "      <td>trung_tâm kiểm_soát bệnh_tật hà_nội lấy mẫu xét_nghiệm kết_quả bệnh_nhân dương_tính ncov</td>\n",
              "      <td>Trung_tâm Kiểm_soát bệnh_tật Hà_Nội lấy mẫu xét_nghiệm kết_quả bệnh_nhân dương_tính nCoV</td>\n",
              "      <td>[B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, O, O, O, O, O, O, O]</td>\n",
              "      <td>11</td>\n",
              "      <td>B-ORGANIZATION I-ORGANIZATION I-ORGANIZATION I-ORGANIZATION O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>&lt;num&gt;h sáng ngày &lt;num&gt;/&lt;num&gt; bệnh_nhân được chuyển đến khoa y_học nhiệt_đới bệnh_viện đà_nẵng</td>\n",
              "      <td>2h sáng ngày 27/7 bệnh_nhân được chuyển đến khoa Y_học nhiệt_đới Bệnh_viện Đà_Nẵng</td>\n",
              "      <td>[O, O, O, B-DATE, O, O, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION]</td>\n",
              "      <td>13</td>\n",
              "      <td>O O O B-DATE O O O O B-LOCATION I-LOCATION I-LOCATION I-LOCATION I-LOCATION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262</th>\n",
              "      <td>hiện bệnh_nhân điều_trị tại bệnh_viện dã_chiến củ_chi</td>\n",
              "      <td>Hiện bệnh_nhân điều_trị tại Bệnh_viện Dã_chiến Củ_Chi</td>\n",
              "      <td>[O, O, O, O, B-LOCATION, I-LOCATION, I-LOCATION]</td>\n",
              "      <td>7</td>\n",
              "      <td>O O O O B-LOCATION I-LOCATION I-LOCATION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1535</th>\n",
              "      <td>bệnh_nhân &lt;num&gt; ở xã khải_xuân huyện thanh_ba tỉnh phú_thọ</td>\n",
              "      <td>Bệnh_nhân 994 ở xã Khải_Xuân huyện Thanh_Ba tỉnh Phú_Thọ</td>\n",
              "      <td>[O, B-PATIENT_ID, O, B-LOCATION, I-LOCATION, B-LOCATION, I-LOCATION, B-LOCATION, I-LOCATION]</td>\n",
              "      <td>9</td>\n",
              "      <td>O B-PATIENT_ID O B-LOCATION I-LOCATION B-LOCATION I-LOCATION B-LOCATION I-LOCATION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4533</th>\n",
              "      <td>vài ngày trước khi có dấu_hiệu sốt bệnh_nhân cùng chồng đến chợ đầu_mối mua_sắm</td>\n",
              "      <td>Vài ngày trước khi có dấu_hiệu sốt bệnh_nhân cùng chồng đến chợ đầu_mối mua_sắm</td>\n",
              "      <td>[O, O, O, O, O, O, B-SYMPTOM_AND_DISEASE, O, O, O, O, O, O, O]</td>\n",
              "      <td>14</td>\n",
              "      <td>O O O O O O B-SYMPTOM_AND_DISEASE O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2955</th>\n",
              "      <td>đến thời_điểm này không có thêm nhân_viên y_tế nào của bạch_mai mắc bệnh</td>\n",
              "      <td>Đến thời_điểm này không có thêm nhân_viên y_tế nào của Bạch_Mai mắc bệnh</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, B-ORGANIZATION, O, O]</td>\n",
              "      <td>13</td>\n",
              "      <td>O O O O O O O O O O B-ORGANIZATION O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3951</th>\n",
              "      <td>từ &lt;num&gt; đến &lt;num&gt; - &lt;num&gt; bệnh_nhân đi ôtô vào tp.hcm.</td>\n",
              "      <td>Từ 27 đến 29 - 7 bệnh_nhân đi ôtô vào TP.HCM.</td>\n",
              "      <td>[O, B-DATE, O, B-DATE, I-DATE, I-DATE, O, O, O, O, B-LOCATION]</td>\n",
              "      <td>11</td>\n",
              "      <td>O B-DATE O B-DATE I-DATE I-DATE O O O O B-LOCATION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>hiện bệnh_nhân có khó thở được đặt thở máy</td>\n",
              "      <td>Hiện bệnh_nhân có khó thở được đặt thở máy</td>\n",
              "      <td>[O, O, O, B-SYMPTOM_AND_DISEASE, I-SYMPTOM_AND_DISEASE, O, O, O, O]</td>\n",
              "      <td>9</td>\n",
              "      <td>O O O B-SYMPTOM_AND_DISEASE I-SYMPTOM_AND_DISEASE O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2661</th>\n",
              "      <td>bệnh_nhân thứ &lt;num&gt; là thanh_niên từ daegu hàn_quốc về nước ngày &lt;num&gt;/&lt;num&gt;</td>\n",
              "      <td>Bệnh_nhân thứ 18 là thanh_niên từ Daegu Hàn_Quốc về nước ngày 4/3</td>\n",
              "      <td>[O, O, B-PATIENT_ID, O, O, O, B-LOCATION, B-LOCATION, O, O, O, B-DATE]</td>\n",
              "      <td>12</td>\n",
              "      <td>O O B-PATIENT_ID O O O B-LOCATION B-LOCATION O O O B-DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4900</th>\n",
              "      <td>các bác_sĩ nhận_định bệnh_nhân &lt;num&gt; là một ca bệnh có tiền_sử dịch_tễ đặc_biệt</td>\n",
              "      <td>Các bác_sĩ nhận_định bệnh_nhân 268 là một ca bệnh có tiền_sử dịch_tễ đặc_biệt</td>\n",
              "      <td>[O, O, O, O, B-PATIENT_ID, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>13</td>\n",
              "      <td>O O O O B-PATIENT_ID O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>ngày &lt;num&gt; - &lt;num&gt; bệnh_nhân cùng đoàn của bệnh_viện bạch_mai_công_tác tại tỉnh hà_nam</td>\n",
              "      <td>Ngày 27 - 3 bệnh_nhân cùng đoàn của Bệnh_viện Bạch_Mai_công_tác tại tỉnh Hà_Nam</td>\n",
              "      <td>[O, B-DATE, I-DATE, I-DATE, O, O, O, O, B-ORGANIZATION, I-ORGANIZATION, O, B-LOCATION, I-LOCATION]</td>\n",
              "      <td>13</td>\n",
              "      <td>O B-DATE I-DATE I-DATE O O O O B-ORGANIZATION I-ORGANIZATION O B-LOCATION I-LOCATION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2132</th>\n",
              "      <td>bệnh_nhân được hướng_dẫn tự cách_ly tại nhà</td>\n",
              "      <td>Bệnh_nhân được hướng_dẫn tự cách_ly tại nhà</td>\n",
              "      <td>[O, O, O, O, O, O, O]</td>\n",
              "      <td>7</td>\n",
              "      <td>O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4770</th>\n",
              "      <td>anh là một trong &lt;num&gt; người khác được xác_nhận nhiễm_bệnh hôm &lt;num&gt; - &lt;num&gt;</td>\n",
              "      <td>Anh là một trong 3 người khác được xác_nhận nhiễm_bệnh hôm 13 - 2</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-DATE, I-DATE, I-DATE]</td>\n",
              "      <td>14</td>\n",
              "      <td>O O O O O O O O O O O B-DATE I-DATE I-DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>ngày &lt;num&gt;/&lt;num&gt; bệnh_nhân thấy tức ngực mệt mẫu xét_nghiệm ngày &lt;num&gt;/&lt;num&gt; kết_quả dương_tính ncov</td>\n",
              "      <td>Ngày 9/7 bệnh_nhân thấy tức ngực mệt mẫu xét_nghiệm ngày 26/7 kết_quả dương_tính nCoV</td>\n",
              "      <td>[O, B-DATE, O, O, B-SYMPTOM_AND_DISEASE, I-SYMPTOM_AND_DISEASE, B-SYMPTOM_AND_DISEASE, O, O, O, B-DATE, O, O, O]</td>\n",
              "      <td>14</td>\n",
              "      <td>O B-DATE O O B-SYMPTOM_AND_DISEASE I-SYMPTOM_AND_DISEASE B-SYMPTOM_AND_DISEASE O O O B-DATE O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1507</th>\n",
              "      <td>quảng_nam là địa_phương ghi_nhận số bệnh_nhân nhiều thứ nhì sau đà_nẵng</td>\n",
              "      <td>Quảng_Nam là địa_phương ghi_nhận số bệnh_nhân nhiều thứ nhì sau Đà_Nẵng</td>\n",
              "      <td>[B-LOCATION, O, O, O, O, O, O, O, O, O, B-LOCATION]</td>\n",
              "      <td>11</td>\n",
              "      <td>B-LOCATION O O O O O O O O O B-LOCATION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3878</th>\n",
              "      <td>hiện bệnh_nhân được cách_ly điều_trị tại bệnh_viện đa_khoa tỉnh bình_dương</td>\n",
              "      <td>Hiện bệnh_nhân được cách_ly điều_trị tại Bệnh_viện Đa_khoa tỉnh Bình_Dương</td>\n",
              "      <td>[O, O, O, O, O, O, B-LOCATION, I-LOCATION, I-LOCATION, I-LOCATION]</td>\n",
              "      <td>10</td>\n",
              "      <td>O O O O O O B-LOCATION I-LOCATION I-LOCATION I-LOCATION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1805</th>\n",
              "      <td>bệnh_nhân là du_khách nhập_cảnh nội_bài ngày &lt;num&gt; - &lt;num&gt; trên chuyến bay su &lt;num&gt;</td>\n",
              "      <td>Bệnh_nhân là du_khách nhập_cảnh Nội_Bài ngày 13 - 3 trên chuyến bay SU 290</td>\n",
              "      <td>[O, O, O, O, B-LOCATION, O, B-DATE, I-DATE, I-DATE, O, O, O, B-TRANSPORTATION, I-TRANSPORTATION]</td>\n",
              "      <td>14</td>\n",
              "      <td>O O O O B-LOCATION O B-DATE I-DATE I-DATE O O O B-TRANSPORTATION I-TRANSPORTATION</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b6522a4-422d-4438-a5c1-363c597c86ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b6522a4-422d-4438-a5c1-363c597c86ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b6522a4-422d-4438-a5c1-363c597c86ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "x003rxWDK-tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_train = {\n",
        "    'mbert': 'bert-base-multilingual-cased',\n",
        "    'xlmr_base': 'xlm-roberta-base',\n",
        "    'xlmr_large': 'xlm-roberta-large',\n",
        "    'phobert': 'vinai/phobert-base'\n",
        "}\n",
        "pre_trained_name = pre_train['xlmr_base']\n",
        "MAX_LEN = 128"
      ],
      "metadata": {
        "id": "1qutlaprxZxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_values = ['O',\n",
        " 'B-ORGANIZATION',\n",
        " 'I-ORGANIZATION',\n",
        " 'B-SYMPTOM_AND_DISEASE',\n",
        " 'I-SYMPTOM_AND_DISEASE',\n",
        " 'B-LOCATION',\n",
        " 'B-DATE',\n",
        " 'B-PATIENT_ID',\n",
        " 'B-AGE',\n",
        " 'B-NAME',\n",
        " 'I-DATE',\n",
        " 'B-JOB',\n",
        " 'I-LOCATION',\n",
        " 'B-TRANSPORTATION',\n",
        " 'B-GENDER',\n",
        " 'I-TRANSPORTATION',\n",
        " 'I-JOB',\n",
        " 'I-NAME',\n",
        " 'I-AGE',\n",
        " 'I-PATIENT_ID']\n",
        "tags = ClassLabel(num_classes=len(tag_values), names=tag_values)"
      ],
      "metadata": {
        "id": "A91UfftyG43t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
        "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}\n",
        "tokenizer = AutoTokenizer.from_pretrained(pre_trained_name, do_lower_case=False,use_fast=True)\n",
        "config = AutoConfig.from_pretrained(pre_trained_name, output_hidden_states=False,\n",
        "                                    id2label=index2tag, label2id=tag2index)\n",
        "# model = AutoModel.from_pretrained(pre_trained_name, config=config)\n",
        "config.hidden_dropout_prob = bert_hidd_dropout\n",
        "config.attention_probs_dropout_prob = bert_att_dropout"
      ],
      "metadata": {
        "id": "UwBeTHH4xT-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without CRF"
      ],
      "metadata": {
        "id": "162se49RLV5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_predictions(predictions, label_ids):\n",
        "  preds = np.argmax(predictions, axis=2)\n",
        "  batch_size, seq_len = preds.shape\n",
        "  labels_list, preds_list = [], []\n",
        "  for batch_idx in range(batch_size):\n",
        "    example_labels, example_preds = [], []\n",
        "    for seq_idx in range(seq_len):\n",
        "      if label_ids[batch_idx, seq_idx] != -100:\n",
        "        example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
        "        example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
        "    labels_list.append(example_labels)\n",
        "    preds_list.append(example_preds)\n",
        "  return preds_list, labels_list\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  print(eval_pred)\n",
        "  y_pred, y_true = align_predictions(eval_pred.predictions,\n",
        "                                     eval_pred.label_ids)\n",
        "  return {\"f1\": f1_score(y_true, y_pred)}"
      ],
      "metadata": {
        "id": "hyY6KorfexxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(r):\n",
        "  X = tokenizer(r['word_process'], \n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                max_length=MAX_LEN)\n",
        "  previous_word_idx = None\n",
        "  label_ids = []\n",
        "  for word_idx in X.word_ids():\n",
        "    if word_idx is None or word_idx == previous_word_idx:\n",
        "      label_ids.append(-100)\n",
        "    elif word_idx != previous_word_idx:\n",
        "      label_ids.append(tag2index[r['tag'][word_idx]])\n",
        "    previous_word_idx = word_idx\n",
        "  return X.input_ids, label_ids\n",
        "\n",
        "def preprocess(df):\n",
        "  df[['tokenized_sentence','tokenized_labels']] = df.apply(lambda x: encode(x),  axis=1, result_type='expand')\n",
        "  return df\n",
        "\n",
        "word_train_data_group = preprocess(word_train_data_group)\n",
        "word_val_data_group = preprocess(word_val_data_group)\n",
        "word_test_data_group = preprocess(word_test_data_group)"
      ],
      "metadata": {
        "id": "_JEPJX0u3xiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
        "  config_class = XLMRobertaConfig\n",
        "  def __init__(self, config, num_layer=197):\n",
        "    super().__init__(config)\n",
        "    self.num_labels = config.num_labels\n",
        "    # Load model body\n",
        "    self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
        "    # cnt = 0\n",
        "    # for param in self.roberta.named_parameters():\n",
        "    #   cnt += 1\n",
        "    #   if cnt>=num_layer:\n",
        "    #       param[1].requires_grad = True\n",
        "    #   else:\n",
        "    #       param[1].requires_grad = False\n",
        "\n",
        "    # Set up token classification head\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    # Load and initialize weights\n",
        "    self.init_weights()\n",
        "  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,labels=None, **kwargs):\n",
        "    # Use model body to get encoder representations\n",
        "    outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
        "    token_type_ids=token_type_ids, **kwargs)\n",
        "    # Apply classifier to encoder representation\n",
        "    sequence_output = self.dropout(outputs[0])\n",
        "    logits = self.classifier(sequence_output)\n",
        "    # Calculate losses\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "    # Return model output object\n",
        "    return TokenClassifierOutput(loss=loss, logits=logits,\n",
        "        hidden_states=outputs.hidden_states,\n",
        "        attentions=outputs.attentions)"
      ],
      "metadata": {
        "id": "5MRWeplevv2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With CRF"
      ],
      "metadata": {
        "id": "SHNfFBuXLZBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_predictions(predictions, label_ids):\n",
        "  preds = predictions\n",
        "  batch_size, seq_len = preds.shape\n",
        "  labels_list, preds_list = [], []\n",
        "  for batch_idx in range(batch_size):\n",
        "    example_labels, example_preds = [], []\n",
        "    for seq_idx in range(seq_len):\n",
        "      if label_ids[batch_idx, seq_idx] != -100:\n",
        "        example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
        "        example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
        "    labels_list.append(example_labels)\n",
        "    preds_list.append(example_preds)\n",
        "  return preds_list, labels_list\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  print(eval_pred)\n",
        "  y_pred, y_true = align_predictions(eval_pred.predictions,\n",
        "                                     eval_pred.label_ids)\n",
        "  return {\"f1\": f1_score(y_true, y_pred)}"
      ],
      "metadata": {
        "id": "Yk9PvjPpRMLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(r):\n",
        "  X = tokenizer(r['word_process'], \n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                max_length=MAX_LEN)\n",
        "  previous_word_idx = None\n",
        "  label_ids = []\n",
        "  label_ids_mask = []\n",
        "  for word_idx in X.word_ids():\n",
        "    if word_idx is None :\n",
        "      label_ids.append(0)\n",
        "    else:\n",
        "      label_ids.append(tag2index[r['tag'][word_idx]])\n",
        "    \n",
        "    if word_idx is None or word_idx == previous_word_idx:\n",
        "      label_ids_mask.append(False)\n",
        "    elif word_idx != previous_word_idx:\n",
        "      label_ids_mask.append(True)\n",
        "    previous_word_idx = word_idx\n",
        "  return X.input_ids, label_ids, label_ids_mask\n",
        "\n",
        "def preprocess(df):\n",
        "  df[['tokenized_sentence','tokenized_labels', 'label_ids_mask']] = df.apply(lambda x: encode(x),  axis=1, result_type='expand')\n",
        "  return df\n",
        "\n",
        "word_train_data_group = preprocess(word_train_data_group)\n",
        "word_val_data_group = preprocess(word_val_data_group)\n",
        "word_test_data_group = preprocess(word_test_data_group)"
      ],
      "metadata": {
        "id": "VY6z-S8wLbNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
        "  config_class = XLMRobertaConfig\n",
        "  def __init__(self, config, num_layer=197):\n",
        "    super().__init__(config)\n",
        "    self.num_labels = config.num_labels\n",
        "    # Load model body\n",
        "    self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
        "    # Set up token classification head\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    self.crf = CRF(num_tags=self.num_labels)\n",
        "    # Load and initialize weights\n",
        "    self.init_weights()\n",
        "  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,labels=None, **kwargs):\n",
        "    outputs = self.roberta(input_ids=input_ids,\n",
        "                        token_type_ids=token_type_ids,\n",
        "                        attention_mask=attention_mask)\n",
        "    sequence_output = self.dropout(outputs[0])\n",
        "    emissions = self.classifier(sequence_output)\n",
        "\n",
        "    if labels is not None:\n",
        "        log_likelihood = self.crf(emissions, labels)\n",
        "        sequence_of_tags = torch.Tensor(self.crf.decode(emissions))\n",
        "        return TokenClassifierOutput(loss=-log_likelihood, logits=torch.Tensor(sequence_of_tags).T)\n",
        "    else:\n",
        "        sequence_of_tags = self.crf.decode(emissions)\n",
        "        return sequence_of_tags"
      ],
      "metadata": {
        "id": "fNpCB3jQMQtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run model"
      ],
      "metadata": {
        "id": "wfIXPa-oMR33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_train_test = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(word_train_data_group[['tokenized_sentence', 'tokenized_labels']].rename(columns={'tokenized_sentence': 'input_ids',\n",
        "                                                                                  'tokenized_labels': 'labels'})),\n",
        "    \"valid\": Dataset.from_pandas(word_val_data_group[['tokenized_sentence', 'tokenized_labels']].rename(columns={'tokenized_sentence': 'input_ids',\n",
        "                                                                                  'tokenized_labels': 'labels'})),\n",
        "    \"test\": Dataset.from_pandas(word_test_data_group[['tokenized_sentence', 'tokenized_labels']].rename(columns={'tokenized_sentence': 'input_ids',\n",
        "                                                                                  'tokenized_labels': 'labels'}))\n",
        "    })\n",
        "datasets_train_test"
      ],
      "metadata": {
        "id": "BFCiwVzSxyFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11dcb4c4-1ad8-489e-cb9b-599a083b2590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'labels', 'idx'],\n",
              "        num_rows: 5027\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['input_ids', 'labels', 'idx'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'labels', 'idx'],\n",
              "        num_rows: 3000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "batch_size = 8\n",
        "\n",
        "def model_init():\n",
        "  return (XLMRobertaForTokenClassification.from_pretrained(pre_trained_name, config=config).to(device))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "      output_dir=pre_trained_name+'_output', log_level=\"error\", num_train_epochs=num_epochs,\n",
        "      per_device_train_batch_size=batch_size,\n",
        "      per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\",\n",
        "      logging_steps=len(datasets_train_test[\"train\"]) // batch_size,\n",
        "       save_steps=1e6, weight_decay=0.01, disable_tqdm=False, push_to_hub=False)\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "trainer = Trainer(model_init=model_init, args=training_args,\n",
        "        data_collator=data_collator, compute_metrics=compute_metrics,\n",
        "        train_dataset=datasets_train_test[\"train\"],\n",
        "        eval_dataset=datasets_train_test[\"valid\"],\n",
        "        tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "coJPnI3PtaJI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b9e503bd178f43e1ad5eac49ecfdfee4",
            "f3990774a689494296fb85faae26d13f",
            "a78ebbc20aaa4142b5f120d47ba8c893",
            "e6cd6b73362841558f20d8addb219ea2",
            "5435290e23f248989eb7a7269d30d605",
            "2674ef1a72844012917176fb95cdf9e3",
            "74afe5822719440fb7bfb454dc808973",
            "43e4fecf62f64de58d837febc13cb5b2",
            "e602944508574965a6f84505d69f84a4",
            "e0fc26ecbcc74939a18a8125bd096ea9",
            "1169359788ec4f8e8972a9fa29a70f23"
          ]
        },
        "outputId": "e870fd74-f982-44f2-fb01-b32f298895a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9e503bd178f43e1ad5eac49ecfdfee4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Without CRF\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "dS0HhP6E0Qqu",
        "outputId": "86ab1489-5240-497d-ad62-8ef40cc6aaae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6290' max='6290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6290/6290 22:38, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.516700</td>\n",
              "      <td>0.200825</td>\n",
              "      <td>0.793147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.132000</td>\n",
              "      <td>0.163368</td>\n",
              "      <td>0.857644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.085500</td>\n",
              "      <td>0.139034</td>\n",
              "      <td>0.890225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.067900</td>\n",
              "      <td>0.124647</td>\n",
              "      <td>0.897166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.052800</td>\n",
              "      <td>0.134440</td>\n",
              "      <td>0.900896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.040500</td>\n",
              "      <td>0.155354</td>\n",
              "      <td>0.909023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.031900</td>\n",
              "      <td>0.152017</td>\n",
              "      <td>0.913629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.025500</td>\n",
              "      <td>0.152288</td>\n",
              "      <td>0.915509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.019700</td>\n",
              "      <td>0.160086</td>\n",
              "      <td>0.921658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.017800</td>\n",
              "      <td>0.165038</td>\n",
              "      <td>0.921875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<transformers.trainer_utils.EvalPrediction object at 0x7fc22e325280>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7fc22e299f10>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7fc22e325280>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7fc22e282070>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7fc22e276640>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7fc22e2d3fa0>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7fc22e1f7fa0>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7fc22e2d3fa0>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7fc22e334f70>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7fc22e1ed730>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6290, training_loss=0.09886944247779861, metrics={'train_runtime': 1361.6486, 'train_samples_per_second': 36.918, 'train_steps_per_second': 4.619, 'total_flos': 1642190696678400.0, 'train_loss': 0.09886944247779861, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#With CRF\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "2R3lTwlFNbNW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "6945db04-89de-42d6-f00a-d10eeb7e932b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:413.)\n",
            "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='584' max='6290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 584/6290 02:54 < 28:29, 3.34 it/s, Epoch 0.93/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6290' max='6290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6290/6290 35:07, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>224.038500</td>\n",
              "      <td>82.966591</td>\n",
              "      <td>0.888035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>59.098800</td>\n",
              "      <td>76.130905</td>\n",
              "      <td>0.910602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>40.466100</td>\n",
              "      <td>69.364769</td>\n",
              "      <td>0.922891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>30.668000</td>\n",
              "      <td>76.120110</td>\n",
              "      <td>0.931034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>25.559800</td>\n",
              "      <td>79.982460</td>\n",
              "      <td>0.939041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>22.267900</td>\n",
              "      <td>87.241516</td>\n",
              "      <td>0.938337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>19.718400</td>\n",
              "      <td>106.996284</td>\n",
              "      <td>0.941807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>17.112500</td>\n",
              "      <td>116.946159</td>\n",
              "      <td>0.943400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>14.626400</td>\n",
              "      <td>120.375656</td>\n",
              "      <td>0.945312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>12.170000</td>\n",
              "      <td>122.105522</td>\n",
              "      <td>0.945768</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<transformers.trainer_utils.EvalPrediction object at 0x7f2fb1697c10>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f2fb1697fd0>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f2fb168af70>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f2fb3004df0>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f2fb5270640>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f2fb169bd30>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f2fb1697c10>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f2fb169bd30>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f2fb3005af0>\n",
            "<transformers.trainer_utils.EvalPrediction object at 0x7f2fb1697b50>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6290, training_loss=46.51228413907826, metrics={'train_runtime': 2110.9578, 'train_samples_per_second': 23.814, 'train_steps_per_second': 2.98, 'total_flos': 3284398380595200.0, 'train_loss': 46.51228413907826, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('xml-r-base-crf')"
      ],
      "metadata": {
        "id": "oB46N5lLfb-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "fY1Cliq4tG09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without CRF"
      ],
      "metadata": {
        "id": "XSDJsWktC3mA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = XLMRobertaForTokenClassification.from_pretrained('/content/drive/MyDrive/xml-r-base', config=config)\n",
        "trainer = Trainer(model=model)\n",
        "x=trainer.predict(datasets_train_test['test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "BYgOpgZgq-Dy",
        "outputId": "f73581c7-4488-45fe-a44d-e8a7c231384c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file /content/drive/MyDrive/xml-r-base/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing XLMRobertaForTokenClassification.\n",
            "\n",
            "All the weights of XLMRobertaForTokenClassification were initialized from the model checkpoint at /content/drive/MyDrive/xml-r-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForTokenClassification for predictions without further training.\n",
            "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForTokenClassification.forward` and have been ignored: idx. If idx are not expected by `XLMRobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.argmax(x.predictions, axis=2)\n",
        "lab = np.array(datasets_train_test['test']['labels'])\n",
        "preds_list, labels_list = align_predictions(x.predictions, lab)\n",
        "print(classification_report(labels_list, preds_list, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx9bNfymtM0N",
        "outputId": "60ddfe43-67c7-472a-86c1-82728e03ad62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE     0.9436    0.9701    0.9567       569\n",
            "               DATE     0.9729    0.9866    0.9797      1639\n",
            "             GENDER     0.9244    0.9800    0.9514       449\n",
            "                JOB     0.5813    0.6821    0.6277       173\n",
            "           LOCATION     0.8938    0.9145    0.9040      4398\n",
            "               NAME     0.8567    0.9123    0.8836       308\n",
            "       ORGANIZATION     0.8230    0.8294    0.8262       768\n",
            "         PATIENT_ID     0.9715    0.9720    0.9717      1962\n",
            "SYMPTOM_AND_DISEASE     0.7549    0.7830    0.7687      1129\n",
            "     TRANSPORTATION     0.9300    0.9637    0.9466       193\n",
            "\n",
            "          micro avg     0.8973    0.9185    0.9078     11588\n",
            "          macro avg     0.8652    0.8994    0.8816     11588\n",
            "       weighted avg     0.8985    0.9185    0.9083     11588\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With CRF"
      ],
      "metadata": {
        "id": "LL6Mch-7C6EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = XLMRobertaForTokenClassification.from_pretrained('/content/drive/MyDrive/xml-r-base-crf', config=config)\n",
        "trainer = Trainer(model=model)\n",
        "x=trainer.predict(datasets_train_test['test'])"
      ],
      "metadata": {
        "id": "W89DePpdLGxn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "4136c996-4f89-4e86-acfc-b9cf0b0dac9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `XLMRobertaForTokenClassification.forward` and have been ignored: idx. If idx are not expected by `XLMRobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.8/dist-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:413.)\n",
            "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask=np.array(word_test_data_group['label_ids_mask'].values.tolist())\n",
        "lab = np.array(datasets_train_test['test']['labels'])\n",
        "labs=[]\n",
        "for ind, l in enumerate(lab):\n",
        "  labs.append(np.where(mask[ind], l, -100))\n",
        "labs = np.array(labs).astype('int')"
      ],
      "metadata": {
        "id": "3hopZpaNDhO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_list, labels_list = align_predictions(x.predictions, labs)\n",
        "print(classification_report(labels_list, preds_list, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwci4HM6Ewvx",
        "outputId": "bbf4f69a-233b-4d5f-bdf2-96b77be029a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE     0.9585    0.9736    0.9660       569\n",
            "               DATE     0.9771    0.9878    0.9824      1639\n",
            "             GENDER     0.9245    0.9822    0.9525       449\n",
            "                JOB     0.6359    0.7168    0.6739       173\n",
            "           LOCATION     0.9112    0.9150    0.9131      4398\n",
            "               NAME     0.9211    0.9091    0.9150       308\n",
            "       ORGANIZATION     0.8032    0.8451    0.8236       768\n",
            "         PATIENT_ID     0.9686    0.9760    0.9723      1962\n",
            "SYMPTOM_AND_DISEASE     0.7819    0.7874    0.7846      1129\n",
            "     TRANSPORTATION     0.9250    0.9585    0.9415       193\n",
            "\n",
            "          micro avg     0.9090    0.9216    0.9153     11588\n",
            "          macro avg     0.8807    0.9052    0.8925     11588\n",
            "       weighted avg     0.9097    0.9216    0.9156     11588\n",
            "\n"
          ]
        }
      ]
    }
  ]
}